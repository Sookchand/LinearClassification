{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Machine Learning and Neurons.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOuxoyar45PbS20/7Nycav5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sookchand/LinearClassification/blob/main/Machine_Learning_and_Neurons.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CiiK7-dN3WNW"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ksct_OQq3j0V"
      },
      "source": [
        "## More Details\n",
        "The main difference between ScikitLearn and Keras is that we are resposible for building the model\n",
        "\n",
        "1. The Architure of the model(the equation to go from input to prediction)\n",
        "2. How is this model trained:\n",
        "  * Cost/loss/error function\n",
        "  * Gradient decent to maximise cost"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N9qlrgrO4ZVX"
      },
      "source": [
        "# What is a line?\n",
        "1. This is just like the usual \"y = mx + b\"\n",
        "2. But for 2-D classification:\n",
        "  * The horizontal axis is x1\n",
        "  * The vertical axis is x2\n",
        "  * It's more conventional to arrange the equation as follows\n",
        "    (even though it could be written as x2 = mx1 + b)\n",
        "    w1x1 + w2x2 + b = 0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e4Dgago873Zh"
      },
      "source": [
        "# The Decision rule\n",
        "How do we use the line to classify?\n",
        "\n",
        "a = w1x1 + w2x2 + b\n",
        "\n",
        "if a >= 0 predict ---> 1\n",
        "\n",
        "if a <= 0 predict ---> 0\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cwnUppqz9G8r"
      },
      "source": [
        "# The Decision Rule\n",
        "* Can be more compactly written as:\n",
        "\n",
        "y = u(a), a = w1x1 + w2x2 + b\n",
        "\n",
        "* In deep learning we prefer smooth diferential function(\"sigmoid\"):\n",
        "\n",
        "y = q(a), a = w1x1 + w2x2 + b\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CKDMbBjh-06F"
      },
      "source": [
        "# Probablistic Interpretation\n",
        "* We normally interpret the output as \"the probabbility that y = 1 given x\"\n",
        "* To make the prediction we round:\n",
        "  * if p(y=1 | x) > 50% ---> predict 1, else 0\n",
        "* The \"S-shaped\" curve is called a sigmoid.\n",
        "* The model is called Logistic Regression.\n",
        "* Sigmoid = Logistic Function.\n",
        "* Its argument is called \"logit\", although a more modern name is called \"activation\"\n",
        "\n",
        "p(y=1 | x) = q(w1x1 + w2x2 + b)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_kS34_zAAzws"
      },
      "source": [
        "# Logistic Regression with 2 > inputs\n",
        "* WHat if we have > 2 inputs like 100 or 1000, etc\n",
        "* No problem! Just use what we know about matirces and vectors\n",
        "\n",
        "p(y=1 | x) = q(W^t x + b) = "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OblXEF09SVwP"
      },
      "source": [
        "Load in the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BKsUD-qgeEvJ"
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3yguDqoZ4UlD"
      },
      "source": [
        "from sklearn.datasets import load_breast_cancer"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wfrY69CsSfsk"
      },
      "source": [
        "# Load the data\n",
        "data = load_breast_cancer()"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JA4BQbP7S0-J",
        "outputId": "ec8e1572-97a2-4aaa-bbb2-64fa87abf029",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Check the type of the data\n",
        "type(data)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "sklearn.utils.Bunch"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AB7YyYCaS-Pb",
        "outputId": "919378b8-6d6e-45ea-9be7-a538a394db9c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Note this is a bunch object\n",
        "# this is basically like a dictionary where you can treat the keys like attributes\n",
        "data.keys()\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['data', 'target', 'target_names', 'DESCR', 'feature_names', 'filename'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t56QqEeWTR1Y",
        "outputId": "417676d4-c28d-4229-fabb-bf6df557d801",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Data (the attributes) means the input data\n",
        "data.data.shape\n",
        "# it has 569 samples, 30 features"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(569, 30)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XHRP9ruAUBsL",
        "outputId": "d4b1a911-50b1-4059-8753-f1d7d9f5afc7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 454
        }
      },
      "source": [
        "# target\n",
        "data.target\n",
        "# The target is 0s and 1s\n",
        "# normaly when you have k targets they are label 0..k-1"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0,\n",
              "       1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "       1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
              "       0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1,\n",
              "       1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0,\n",
              "       0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0,\n",
              "       1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1,\n",
              "       1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0,\n",
              "       0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0,\n",
              "       0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n",
              "       1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1,\n",
              "       1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1,\n",
              "       1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
              "       1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
              "       1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1,\n",
              "       1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YS47A6ueUL-N",
        "outputId": "4f1b257e-6088-48d6-f8fa-a75b65c90a84",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# their meaning is not lost\n",
        "data.target_names"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['malignant', 'benign'], dtype='<U9')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FT-7alWCV0Cn",
        "outputId": "43a76c32-bc51-48ec-e237-970cacd0fd37",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# there are alos 569 coresponding target\n",
        "data.target.shape"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(569,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rfwCZy4JWK67",
        "outputId": "d5259a56-24b7-4cf2-f656-4b824da9ec9e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        }
      },
      "source": [
        "# You can also determine the input of each feature name\n",
        "data.feature_names"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['mean radius', 'mean texture', 'mean perimeter', 'mean area',\n",
              "       'mean smoothness', 'mean compactness', 'mean concavity',\n",
              "       'mean concave points', 'mean symmetry', 'mean fractal dimension',\n",
              "       'radius error', 'texture error', 'perimeter error', 'area error',\n",
              "       'smoothness error', 'compactness error', 'concavity error',\n",
              "       'concave points error', 'symmetry error',\n",
              "       'fractal dimension error', 'worst radius', 'worst texture',\n",
              "       'worst perimeter', 'worst area', 'worst smoothness',\n",
              "       'worst compactness', 'worst concavity', 'worst concave points',\n",
              "       'worst symmetry', 'worst fractal dimension'], dtype='<U23')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PQ51-k7PWj1p"
      },
      "source": [
        "# Going to split the data into train and test\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# split the data into train and tes sets\n",
        "x_train, x_test, y_train, y_test = train_test_split(data.data, data.target, test_size=0.33)\n",
        "N, D = x_train.shape"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SPIUcqX9YkOQ"
      },
      "source": [
        "# scale the data\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "x_train = scaler.fit_transform(x_train)\n",
        "x_test = scaler.transform(x_test)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kaH0ZEZLZx1n",
        "outputId": "ed620588-f79d-479a-c96a-bb186b849550",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Now all the fun tensorflow stuff\n",
        "# Build the model\n",
        "\n",
        "model = tf.keras.models.Sequential([\n",
        "                                    tf.keras.layers.Input(shape=(D,)),\n",
        "                                    tf.keras.layers.Dense(1, activation=\"sigmoid\")\n",
        "])\n",
        "# Alternatively\n",
        "# model = tf.keras.models.sequential()\n",
        "# model.add(tf.keras.layers.Dense(1, input_shape(D,), activation = \"sigmoid\"))\n",
        "\n",
        "model.compile(optimizer=\"Adam\",\n",
        "              loss = \"binary_crossentropy\",\n",
        "              metrics = \"accuracy\")\n",
        "\n",
        "# train the model\n",
        "r = model.fit(x_train, y_train, validation_data = (x_test, y_test), epochs = 100)\n",
        "\n",
        "#Evaluate the model - evaluate() returns loss and accuracy\n",
        "print(\"Train Score:\", model.evaluate(x_train, y_train))\n",
        "print (\"Test Score:\", model.evaluate(x_test, y_test))\n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.5183 - accuracy: 0.7822 - val_loss: 0.4713 - val_accuracy: 0.8511\n",
            "Epoch 2/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4726 - accuracy: 0.8163 - val_loss: 0.4287 - val_accuracy: 0.8883\n",
            "Epoch 3/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4350 - accuracy: 0.8320 - val_loss: 0.3934 - val_accuracy: 0.8883\n",
            "Epoch 4/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4030 - accuracy: 0.8583 - val_loss: 0.3644 - val_accuracy: 0.8936\n",
            "Epoch 5/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3766 - accuracy: 0.8819 - val_loss: 0.3403 - val_accuracy: 0.9043\n",
            "Epoch 6/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3538 - accuracy: 0.9055 - val_loss: 0.3199 - val_accuracy: 0.9149\n",
            "Epoch 7/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3342 - accuracy: 0.9134 - val_loss: 0.3030 - val_accuracy: 0.9255\n",
            "Epoch 8/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3172 - accuracy: 0.9239 - val_loss: 0.2874 - val_accuracy: 0.9415\n",
            "Epoch 9/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3018 - accuracy: 0.9318 - val_loss: 0.2742 - val_accuracy: 0.9574\n",
            "Epoch 10/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.2883 - accuracy: 0.9370 - val_loss: 0.2624 - val_accuracy: 0.9574\n",
            "Epoch 11/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.2763 - accuracy: 0.9370 - val_loss: 0.2517 - val_accuracy: 0.9574\n",
            "Epoch 12/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.2648 - accuracy: 0.9370 - val_loss: 0.2422 - val_accuracy: 0.9574\n",
            "Epoch 13/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.2550 - accuracy: 0.9370 - val_loss: 0.2334 - val_accuracy: 0.9574\n",
            "Epoch 14/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.2456 - accuracy: 0.9396 - val_loss: 0.2257 - val_accuracy: 0.9574\n",
            "Epoch 15/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.2370 - accuracy: 0.9423 - val_loss: 0.2187 - val_accuracy: 0.9574\n",
            "Epoch 16/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.2291 - accuracy: 0.9423 - val_loss: 0.2121 - val_accuracy: 0.9574\n",
            "Epoch 17/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.2219 - accuracy: 0.9449 - val_loss: 0.2059 - val_accuracy: 0.9628\n",
            "Epoch 18/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.2152 - accuracy: 0.9475 - val_loss: 0.2001 - val_accuracy: 0.9628\n",
            "Epoch 19/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.2088 - accuracy: 0.9501 - val_loss: 0.1949 - val_accuracy: 0.9628\n",
            "Epoch 20/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.2030 - accuracy: 0.9501 - val_loss: 0.1900 - val_accuracy: 0.9628\n",
            "Epoch 21/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.1973 - accuracy: 0.9528 - val_loss: 0.1856 - val_accuracy: 0.9628\n",
            "Epoch 22/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.1924 - accuracy: 0.9528 - val_loss: 0.1813 - val_accuracy: 0.9628\n",
            "Epoch 23/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.1874 - accuracy: 0.9528 - val_loss: 0.1772 - val_accuracy: 0.9628\n",
            "Epoch 24/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.1830 - accuracy: 0.9554 - val_loss: 0.1735 - val_accuracy: 0.9628\n",
            "Epoch 25/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.1786 - accuracy: 0.9554 - val_loss: 0.1700 - val_accuracy: 0.9628\n",
            "Epoch 26/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.1745 - accuracy: 0.9580 - val_loss: 0.1666 - val_accuracy: 0.9628\n",
            "Epoch 27/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.1708 - accuracy: 0.9606 - val_loss: 0.1634 - val_accuracy: 0.9628\n",
            "Epoch 28/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.1672 - accuracy: 0.9659 - val_loss: 0.1604 - val_accuracy: 0.9628\n",
            "Epoch 29/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.1637 - accuracy: 0.9659 - val_loss: 0.1576 - val_accuracy: 0.9628\n",
            "Epoch 30/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.1606 - accuracy: 0.9685 - val_loss: 0.1550 - val_accuracy: 0.9628\n",
            "Epoch 31/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.1574 - accuracy: 0.9685 - val_loss: 0.1524 - val_accuracy: 0.9628\n",
            "Epoch 32/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.1545 - accuracy: 0.9711 - val_loss: 0.1500 - val_accuracy: 0.9628\n",
            "Epoch 33/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.1517 - accuracy: 0.9711 - val_loss: 0.1476 - val_accuracy: 0.9628\n",
            "Epoch 34/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.1490 - accuracy: 0.9711 - val_loss: 0.1455 - val_accuracy: 0.9628\n",
            "Epoch 35/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.1465 - accuracy: 0.9711 - val_loss: 0.1433 - val_accuracy: 0.9628\n",
            "Epoch 36/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.1441 - accuracy: 0.9711 - val_loss: 0.1413 - val_accuracy: 0.9628\n",
            "Epoch 37/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.1418 - accuracy: 0.9711 - val_loss: 0.1394 - val_accuracy: 0.9628\n",
            "Epoch 38/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.1395 - accuracy: 0.9711 - val_loss: 0.1376 - val_accuracy: 0.9628\n",
            "Epoch 39/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.1374 - accuracy: 0.9711 - val_loss: 0.1357 - val_accuracy: 0.9628\n",
            "Epoch 40/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1353 - accuracy: 0.9711 - val_loss: 0.1341 - val_accuracy: 0.9628\n",
            "Epoch 41/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.1334 - accuracy: 0.9711 - val_loss: 0.1324 - val_accuracy: 0.9628\n",
            "Epoch 42/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.1315 - accuracy: 0.9711 - val_loss: 0.1308 - val_accuracy: 0.9628\n",
            "Epoch 43/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.1297 - accuracy: 0.9738 - val_loss: 0.1294 - val_accuracy: 0.9628\n",
            "Epoch 44/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.1280 - accuracy: 0.9738 - val_loss: 0.1279 - val_accuracy: 0.9628\n",
            "Epoch 45/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.1263 - accuracy: 0.9738 - val_loss: 0.1265 - val_accuracy: 0.9681\n",
            "Epoch 46/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.1247 - accuracy: 0.9738 - val_loss: 0.1251 - val_accuracy: 0.9734\n",
            "Epoch 47/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.1231 - accuracy: 0.9738 - val_loss: 0.1238 - val_accuracy: 0.9734\n",
            "Epoch 48/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.1216 - accuracy: 0.9738 - val_loss: 0.1227 - val_accuracy: 0.9734\n",
            "Epoch 49/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.1202 - accuracy: 0.9738 - val_loss: 0.1214 - val_accuracy: 0.9734\n",
            "Epoch 50/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.1188 - accuracy: 0.9738 - val_loss: 0.1203 - val_accuracy: 0.9734\n",
            "Epoch 51/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.1174 - accuracy: 0.9764 - val_loss: 0.1192 - val_accuracy: 0.9734\n",
            "Epoch 52/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.1161 - accuracy: 0.9764 - val_loss: 0.1180 - val_accuracy: 0.9734\n",
            "Epoch 53/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.1148 - accuracy: 0.9764 - val_loss: 0.1169 - val_accuracy: 0.9734\n",
            "Epoch 54/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.1136 - accuracy: 0.9764 - val_loss: 0.1161 - val_accuracy: 0.9734\n",
            "Epoch 55/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.1124 - accuracy: 0.9790 - val_loss: 0.1151 - val_accuracy: 0.9734\n",
            "Epoch 56/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.1113 - accuracy: 0.9816 - val_loss: 0.1141 - val_accuracy: 0.9734\n",
            "Epoch 57/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.1101 - accuracy: 0.9816 - val_loss: 0.1132 - val_accuracy: 0.9734\n",
            "Epoch 58/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.1090 - accuracy: 0.9816 - val_loss: 0.1123 - val_accuracy: 0.9734\n",
            "Epoch 59/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.1080 - accuracy: 0.9816 - val_loss: 0.1114 - val_accuracy: 0.9734\n",
            "Epoch 60/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.1069 - accuracy: 0.9816 - val_loss: 0.1106 - val_accuracy: 0.9734\n",
            "Epoch 61/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.1059 - accuracy: 0.9816 - val_loss: 0.1099 - val_accuracy: 0.9734\n",
            "Epoch 62/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.1050 - accuracy: 0.9816 - val_loss: 0.1090 - val_accuracy: 0.9787\n",
            "Epoch 63/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.1040 - accuracy: 0.9816 - val_loss: 0.1083 - val_accuracy: 0.9787\n",
            "Epoch 64/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.1031 - accuracy: 0.9816 - val_loss: 0.1076 - val_accuracy: 0.9787\n",
            "Epoch 65/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.1022 - accuracy: 0.9816 - val_loss: 0.1069 - val_accuracy: 0.9787\n",
            "Epoch 66/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.1013 - accuracy: 0.9816 - val_loss: 0.1062 - val_accuracy: 0.9787\n",
            "Epoch 67/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.1004 - accuracy: 0.9816 - val_loss: 0.1055 - val_accuracy: 0.9787\n",
            "Epoch 68/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0996 - accuracy: 0.9816 - val_loss: 0.1049 - val_accuracy: 0.9787\n",
            "Epoch 69/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0988 - accuracy: 0.9816 - val_loss: 0.1043 - val_accuracy: 0.9787\n",
            "Epoch 70/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0980 - accuracy: 0.9816 - val_loss: 0.1037 - val_accuracy: 0.9787\n",
            "Epoch 71/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0973 - accuracy: 0.9816 - val_loss: 0.1031 - val_accuracy: 0.9787\n",
            "Epoch 72/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0965 - accuracy: 0.9843 - val_loss: 0.1025 - val_accuracy: 0.9787\n",
            "Epoch 73/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0957 - accuracy: 0.9843 - val_loss: 0.1019 - val_accuracy: 0.9787\n",
            "Epoch 74/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0950 - accuracy: 0.9843 - val_loss: 0.1013 - val_accuracy: 0.9787\n",
            "Epoch 75/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0943 - accuracy: 0.9843 - val_loss: 0.1008 - val_accuracy: 0.9787\n",
            "Epoch 76/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0936 - accuracy: 0.9869 - val_loss: 0.1004 - val_accuracy: 0.9840\n",
            "Epoch 77/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0930 - accuracy: 0.9869 - val_loss: 0.0998 - val_accuracy: 0.9840\n",
            "Epoch 78/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0923 - accuracy: 0.9869 - val_loss: 0.0993 - val_accuracy: 0.9840\n",
            "Epoch 79/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0917 - accuracy: 0.9869 - val_loss: 0.0989 - val_accuracy: 0.9840\n",
            "Epoch 80/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0911 - accuracy: 0.9869 - val_loss: 0.0985 - val_accuracy: 0.9840\n",
            "Epoch 81/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0904 - accuracy: 0.9869 - val_loss: 0.0981 - val_accuracy: 0.9840\n",
            "Epoch 82/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0898 - accuracy: 0.9869 - val_loss: 0.0976 - val_accuracy: 0.9840\n",
            "Epoch 83/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0893 - accuracy: 0.9869 - val_loss: 0.0972 - val_accuracy: 0.9840\n",
            "Epoch 84/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0887 - accuracy: 0.9869 - val_loss: 0.0968 - val_accuracy: 0.9840\n",
            "Epoch 85/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0881 - accuracy: 0.9869 - val_loss: 0.0964 - val_accuracy: 0.9840\n",
            "Epoch 86/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0875 - accuracy: 0.9869 - val_loss: 0.0960 - val_accuracy: 0.9840\n",
            "Epoch 87/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0870 - accuracy: 0.9869 - val_loss: 0.0956 - val_accuracy: 0.9840\n",
            "Epoch 88/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0864 - accuracy: 0.9869 - val_loss: 0.0952 - val_accuracy: 0.9840\n",
            "Epoch 89/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0859 - accuracy: 0.9869 - val_loss: 0.0948 - val_accuracy: 0.9840\n",
            "Epoch 90/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0854 - accuracy: 0.9869 - val_loss: 0.0945 - val_accuracy: 0.9840\n",
            "Epoch 91/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0849 - accuracy: 0.9869 - val_loss: 0.0942 - val_accuracy: 0.9840\n",
            "Epoch 92/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0844 - accuracy: 0.9869 - val_loss: 0.0939 - val_accuracy: 0.9840\n",
            "Epoch 93/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0839 - accuracy: 0.9869 - val_loss: 0.0935 - val_accuracy: 0.9840\n",
            "Epoch 94/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0835 - accuracy: 0.9869 - val_loss: 0.0932 - val_accuracy: 0.9840\n",
            "Epoch 95/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0830 - accuracy: 0.9869 - val_loss: 0.0929 - val_accuracy: 0.9840\n",
            "Epoch 96/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0825 - accuracy: 0.9869 - val_loss: 0.0926 - val_accuracy: 0.9840\n",
            "Epoch 97/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0821 - accuracy: 0.9869 - val_loss: 0.0923 - val_accuracy: 0.9840\n",
            "Epoch 98/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0816 - accuracy: 0.9869 - val_loss: 0.0920 - val_accuracy: 0.9840\n",
            "Epoch 99/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0812 - accuracy: 0.9869 - val_loss: 0.0919 - val_accuracy: 0.9840\n",
            "Epoch 100/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0807 - accuracy: 0.9869 - val_loss: 0.0916 - val_accuracy: 0.9840\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0805 - accuracy: 0.9869\n",
            "Train Score: [0.08048451691865921, 0.9868766665458679]\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.0916 - accuracy: 0.9840\n",
            "Test Score: [0.0915863960981369, 0.9840425252914429]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0MadgHMGdoc1",
        "outputId": "cba53918-ee5d-4cca-d916-9285dc356c49",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "# plot the accuracy\n",
        "plt.plot(r.history[\"accuracy\"], label = \"acc\")\n",
        "plt.plot(r.history[\"val_accuracy\"], label = \"val_acc\")\n",
        "plt.legend()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7fdb36c49208>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o7725olI85n5",
        "outputId": "7248ece2-4ee2-45c6-854f-56b2dfa03e6c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "source": [
        "plt.plot(r.history[\"loss\"], label = \"loss\")\n",
        "plt.plot(r.history[\"val_loss\"], label = \"val_loss\")\n",
        "plt.legend()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7fdb36760518>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MbytEcIZk3da",
        "outputId": "4f905f78-47a4-44f0-872d-46c02f030e23",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "p = model.predict(x_test)\n",
        "print(p) # they are ouputs of the sigmoid interpreted as probabilities p(y = 1 | x)\n",
        "# Round to get the actual predictions\n",
        "# note: has to be flattened since the target are size (N, ) while predictions are size (N, 1)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[9.8042828e-01]\n",
            " [9.8385167e-01]\n",
            " [9.7923553e-01]\n",
            " [9.9615622e-01]\n",
            " [9.3330956e-01]\n",
            " [9.2871475e-01]\n",
            " [9.9139869e-01]\n",
            " [9.8863427e-05]\n",
            " [2.3820400e-03]\n",
            " [6.8772209e-01]\n",
            " [8.8608968e-01]\n",
            " [9.9993503e-01]\n",
            " [2.1841621e-05]\n",
            " [8.4810716e-05]\n",
            " [8.0462290e-05]\n",
            " [9.9928862e-01]\n",
            " [4.2993724e-03]\n",
            " [6.0078502e-04]\n",
            " [9.9918753e-01]\n",
            " [9.9988616e-01]\n",
            " [8.7636924e-01]\n",
            " [9.9664807e-01]\n",
            " [2.9533952e-02]\n",
            " [9.9606895e-01]\n",
            " [9.9882412e-01]\n",
            " [4.5705438e-03]\n",
            " [1.2788177e-04]\n",
            " [6.3561881e-01]\n",
            " [6.5677142e-01]\n",
            " [5.4545628e-05]\n",
            " [8.7007391e-01]\n",
            " [1.5556812e-04]\n",
            " [9.4720572e-01]\n",
            " [9.9856853e-01]\n",
            " [1.3744122e-01]\n",
            " [3.1285584e-03]\n",
            " [9.6275723e-01]\n",
            " [1.8303983e-05]\n",
            " [9.6769333e-03]\n",
            " [9.9706602e-01]\n",
            " [8.0009699e-03]\n",
            " [9.9367142e-01]\n",
            " [1.7686787e-05]\n",
            " [9.9966735e-01]\n",
            " [1.4710426e-04]\n",
            " [8.2662135e-01]\n",
            " [9.9861449e-01]\n",
            " [1.0380632e-05]\n",
            " [9.9278688e-01]\n",
            " [3.0197236e-06]\n",
            " [9.8196268e-01]\n",
            " [8.3724904e-01]\n",
            " [8.0347061e-04]\n",
            " [8.6623132e-03]\n",
            " [9.8978281e-01]\n",
            " [9.8850715e-01]\n",
            " [2.2466421e-02]\n",
            " [9.6994531e-01]\n",
            " [8.1608295e-03]\n",
            " [9.9704254e-01]\n",
            " [1.0283372e-01]\n",
            " [8.4680092e-01]\n",
            " [8.1974649e-05]\n",
            " [9.9875832e-01]\n",
            " [6.1661723e-08]\n",
            " [9.9428165e-01]\n",
            " [2.7368993e-02]\n",
            " [9.9866509e-01]\n",
            " [1.6218394e-02]\n",
            " [4.3333471e-03]\n",
            " [7.3556054e-01]\n",
            " [1.6075373e-04]\n",
            " [9.8124951e-01]\n",
            " [6.9745231e-01]\n",
            " [9.9644589e-01]\n",
            " [1.0501772e-02]\n",
            " [8.4380955e-02]\n",
            " [9.6976453e-01]\n",
            " [9.9517322e-01]\n",
            " [9.8161292e-01]\n",
            " [9.9816048e-01]\n",
            " [1.4826119e-02]\n",
            " [4.3962203e-08]\n",
            " [2.2615194e-02]\n",
            " [9.9459225e-01]\n",
            " [3.8254261e-04]\n",
            " [9.9924624e-01]\n",
            " [1.9088984e-03]\n",
            " [5.7439506e-02]\n",
            " [9.9940735e-01]\n",
            " [9.9092400e-01]\n",
            " [8.7570190e-01]\n",
            " [9.6893615e-01]\n",
            " [9.8206723e-01]\n",
            " [9.8739141e-01]\n",
            " [2.3376942e-04]\n",
            " [3.0931711e-01]\n",
            " [5.5684090e-02]\n",
            " [9.9922925e-01]\n",
            " [9.9429303e-01]\n",
            " [8.3273649e-04]\n",
            " [9.9880373e-01]\n",
            " [1.3866723e-03]\n",
            " [9.4648182e-01]\n",
            " [5.3874904e-01]\n",
            " [9.6540010e-05]\n",
            " [9.9201238e-01]\n",
            " [7.7605033e-01]\n",
            " [2.0199716e-03]\n",
            " [9.9758720e-01]\n",
            " [9.8807704e-01]\n",
            " [9.9874771e-01]\n",
            " [9.5386732e-01]\n",
            " [1.0957668e-04]\n",
            " [9.6348810e-01]\n",
            " [9.3713474e-01]\n",
            " [9.5872402e-01]\n",
            " [5.6947738e-01]\n",
            " [9.9608469e-01]\n",
            " [9.2154551e-01]\n",
            " [1.2313719e-04]\n",
            " [8.8719821e-01]\n",
            " [8.8529909e-01]\n",
            " [9.9757326e-01]\n",
            " [9.9306262e-01]\n",
            " [1.1168185e-01]\n",
            " [1.6914606e-02]\n",
            " [7.6664907e-01]\n",
            " [9.9693930e-01]\n",
            " [7.0221722e-03]\n",
            " [9.0694427e-04]\n",
            " [9.9963814e-01]\n",
            " [8.1040867e-05]\n",
            " [9.9869847e-01]\n",
            " [9.8439014e-01]\n",
            " [8.0420077e-01]\n",
            " [9.9376285e-01]\n",
            " [9.9900222e-01]\n",
            " [9.7470564e-01]\n",
            " [9.9834007e-01]\n",
            " [9.7322899e-01]\n",
            " [8.6040711e-01]\n",
            " [3.5550594e-03]\n",
            " [9.9396360e-01]\n",
            " [9.9441314e-01]\n",
            " [4.8426384e-05]\n",
            " [6.9012858e-05]\n",
            " [8.5950369e-01]\n",
            " [9.9967837e-01]\n",
            " [9.7267294e-01]\n",
            " [7.4911118e-04]\n",
            " [9.9916768e-01]\n",
            " [7.5320172e-01]\n",
            " [9.9234676e-01]\n",
            " [8.3858705e-01]\n",
            " [1.1984110e-02]\n",
            " [7.7577293e-01]\n",
            " [9.3280274e-01]\n",
            " [9.9485970e-01]\n",
            " [3.4403801e-04]\n",
            " [2.0012617e-02]\n",
            " [9.9731934e-01]\n",
            " [8.8015795e-03]\n",
            " [9.9905050e-01]\n",
            " [9.9680865e-01]\n",
            " [8.0397131e-06]\n",
            " [1.1465549e-03]\n",
            " [5.2082807e-02]\n",
            " [5.1600081e-01]\n",
            " [2.0388570e-05]\n",
            " [9.9685478e-01]\n",
            " [1.6148651e-01]\n",
            " [6.1496794e-03]\n",
            " [9.7690719e-01]\n",
            " [5.8668731e-05]\n",
            " [1.6817451e-04]\n",
            " [9.5913649e-01]\n",
            " [9.9748814e-01]\n",
            " [9.5869213e-01]\n",
            " [9.4607341e-01]\n",
            " [9.8777944e-01]\n",
            " [1.1863023e-02]\n",
            " [9.9990344e-01]\n",
            " [1.3796852e-08]\n",
            " [9.9795806e-01]\n",
            " [5.2097499e-02]\n",
            " [3.2793194e-01]\n",
            " [5.4113549e-01]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "16x5Qkzdk4fO",
        "outputId": "85cfecd6-fd6c-47c4-e34b-f21764622f23",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        }
      },
      "source": [
        "import numpy as np\n",
        "p = np.round(p).flatten()\n",
        "print(p)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 0. 0. 0. 1. 0. 0. 1. 1. 1. 1. 0. 1.\n",
            " 1. 0. 0. 1. 1. 0. 1. 0. 1. 1. 0. 0. 1. 0. 0. 1. 0. 1. 0. 1. 0. 1. 1. 0.\n",
            " 1. 0. 1. 1. 0. 0. 1. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 0. 1. 0.\n",
            " 1. 1. 1. 0. 0. 1. 1. 1. 1. 0. 0. 0. 1. 0. 1. 0. 0. 1. 1. 1. 1. 1. 1. 0.\n",
            " 0. 0. 1. 1. 0. 1. 0. 1. 1. 0. 1. 1. 0. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1.\n",
            " 0. 1. 1. 1. 1. 0. 0. 1. 1. 0. 0. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1.\n",
            " 1. 0. 0. 1. 1. 1. 0. 1. 1. 1. 1. 0. 1. 1. 1. 0. 0. 1. 0. 1. 1. 0. 0. 0.\n",
            " 1. 0. 1. 0. 0. 1. 0. 0. 1. 1. 1. 1. 1. 0. 1. 0. 1. 0. 0. 1.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "10a7QbmIljzd",
        "outputId": "f204f60b-f77d-4d8c-94aa-b00ac085b9a9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "# Calculate the accuracy, compare it to evaluate()output\n",
        "print(\"Manaual caluculated accuracy:\", np.mean(p == y_test))\n",
        "print(\"Evaluate output:\", model.evaluate(x_test, y_test))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Manaual caluculated accuracy: 0.9840425531914894\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.0916 - accuracy: 0.9840\n",
            "Evaluate output: [0.0915863960981369, 0.9840425252914429]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ySFRAPfImbpo"
      },
      "source": [
        "# Lets save the mdoel to the file\n",
        "model.save(\"linearclassifier.h5\")"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NAH8kk1Aq9cT",
        "outputId": "213e5733-7862-477a-fc06-1db12428d007",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "# Check that the model file exist\n",
        "!ls -lh"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 24K\n",
            "-rw-r--r-- 1 root root  19K Oct 26 20:49 linearclassifier.h5\n",
            "drwxr-xr-x 1 root root 4.0K Oct 14 16:31 sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jezfB19HrPXi",
        "outputId": "5ccbf998-c470-4070-ac6b-f066dada07aa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "# Lets load the model and confirm that it still works\n",
        "model = tf.keras.models.load_model(\"linearclassifier.h5\")\n",
        "print(model.layers)\n",
        "model.evaluate(x_test, y_test)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[<tensorflow.python.keras.layers.core.Dense object at 0x7fdb355f9cf8>]\n",
            "6/6 [==============================] - 0s 1ms/step - loss: 0.0916 - accuracy: 0.9840\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.0915863960981369, 0.9840425252914429]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZvYyI3I0sQZM"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}